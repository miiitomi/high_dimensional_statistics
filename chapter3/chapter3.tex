\documentclass[aspectratio=169, dvipdfmx]{beamer}
\usetheme{Boadilla}
\usepackage{amsmath, amssymb, amsthm, color, latexsym}
\usefonttheme{professionalfonts}

\def\qed{\hfill $\Box$}
\newcommand{\ex}{\mathbb{E}}
\newcommand{\var}{\mathrm{var}}

\title{3. Concentration of measure}
\author{Yoji Tomita}
\date{May 12, 2021}

\begin{document}

\maketitle

\begin{frame}{Introduction}
\begin{itemize}
    \item 2章を前提として, この章ではtail boundやconcentration inequalitiesを求めるためのより上級的な手法を紹介する.
    \item 3.1：Concentration by entropic techniques
    \item 3.2：A geometric perspective on concentration
    \item 3.3：Wasserstein distances and information inequalities
    \item 3.4：Tail bounds for empirical processes
\end{itemize}
\end{frame}

\section{3.1 Concentration by entropic techniques}

\begin{frame}{3.1 Concentration by entropic techniques}
\begin{itemize}
    \item エントロピーと, 集中不等式導出のためのその関連テクニックに関する議論から始める.
\end{itemize}
\end{frame}

\subsection{3.1.1 Entropy and its properties}
\begin{frame}{3.1.1 Entropy and its properties}
\begin{itemize}
    \item 凸関数 $\phi:\mathbb{R} \to \mathbb{R}$と, 確率変数$X\sim \mathbb{P}$に対して, $\phi$-entropyを
    \[\mathbb{H}_\phi(X) := \ex[\phi(X)] - \phi(\ex[X])\]
    とする($X, \phi(X)$の有限期待値は仮定).\\
    　
    \item Jensenの不等式より, $\phi$-entropyは非負.
    \item これは$X$のばらつき加減を表す.
    \begin{itemize}
        \item 極端な場合, $X$がa.s.で期待値と一致するなら, $\mathbb{H}_\phi(X) = 0$.
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\begin{itemize}
    \item 例1：$\phi(u) = u^2$なら$\mathbb{H}_\phi(X)$は分散.
        \[ \mathbb{H}_\phi(X) = \ex[X^2] - (\ex[X])^2 = \var(X).\]
    　
    \item 例2：$\phi(u) = -\log u$, $Z := e^{\lambda X}$とすると,
        \[ \mathbb{H}_\phi(e^{\lambda X})  = -\lambda \ex[X] + \log \ex[e^{\lambda X}] = \log\ex[e^{\lambda(X-\ex[X])}]\]
        となり, centerd cumulant generating functionとなる.
\end{itemize}
\end{frame}

\begin{frame}
    \begin{itemize}
        \item この章では, 次の凸関数$\phi:[0,\infty)\to\mathbb{R}$に対するentropyを考える.
        \[\phi(u) := 
            \begin{cases}
                u\log u & \mathrm{for} \ u > 0\\
                0       & \mathrm{for} \ u = 0
            \end{cases}.\tag{3.1}\label{3.1}
        \]
        非負確率変数$Z$に対して, $\phi$-entropyは
        \[ \mathbb{H}(Z) = \ex[Z\log Z] - \ex[Z]\log\ex[Z], \tag{3.2}\label{3.2}\]
        となる(ただし関連する期待値の存在は仮定). 
        \begin{itemize}
            \item Shannon entropyやKullback-Leibler divergenceと関連がある(see Exercise 3.1).
            \item 以後このentropyを考えるので, $\mathbb{H}_\phi$のsubscrript $\phi$は省略.
        \end{itemize}
        　
        \item $Z = e^{\lambda X}$とすると, $\mathbb{H}(e^{\lambda X})$は$X$のモーメント母関数$\varphi_X(\lambda)=\ex[e^{\lambda X}]$とその導関数$\phi_X'(\lambda)$で表せる.
        \[\mathbb{H}(e^{\lambda X}) = \lambda \varphi_X'(\lambda) - \varphi_X(\lambda)\log\varphi_X(\lambda). \tag{3.3}\label{3.3}\]
    \end{itemize}
\end{frame}

\begin{frame}
\begin{exampleblock}{Example 3.1 (Entropy of a Gauusian random variable)}
    \begin{itemize}
        \item $X$は1次元正規分布$X\sim \mathcal{N}(0, \sigma^2)$とすると, $\varphi_X(\lambda) = e^{\lambda^2\sigma^2/2}, \varphi_X'(\lambda) = \lambda \sigma^2\varphi_X(\lambda)$なので,
        \[ \mathbb{H}(E^{\lambda X}) = \lambda^2\sigma^2\varphi_X(\lambda) - \frac{1}{2}\lambda^2\sigma^2\varphi_X(\lambda) = \frac{1}{2}\lambda^2\sigma^2\varphi_X(\lambda). \tag{3.4}\label{3.4}\]
    \end{itemize}
\end{exampleblock}
　\\
\begin{itemize}
    \item この節の残りで, このエントロピー(\ref{3.3})とtail boundsとの関連性を説明していく.
\end{itemize}
\end{frame}

\subsection{3.1.2 Herbst argument and its extensions}
\begin{frame}{3.1.2 Herbst argument and its extensions}
\begin{itemize}
    \item ある定数$\sigma > 0$が存在して, エントロピーが次の上限を満たすとする.
    \[ \mathbb{H}(e^{\lambda X}) \le \frac{1}{2}\sigma^2 \lambda^2\varphi_X(\lambda).\tag{3.5}\label{3.5} \]
    \begin{itemize}
        \item Example 3.1より, 正規分布$X\sim \mathcal{N}(0,\sigma^2)$は任意の$\lambda \in \mathbb{R}$に対し(3.5)をイコールで満たす.
        \item また任意のboundedな確率変数も(\ref{3.5})を満たす(Exercise 3.7).
    \end{itemize}
    \item このとき, その確率変数はsub-Gaussianとなる.
\end{itemize}
\begin{block}{Proposition 3.2 (Herbst argument)}
    エントロピー$\mathbb{H}(e^{\lambda X})$が(\ref{3.5})を任意の$\lambda \in I$ (ただし$I=[0, \infty)\ \mathrm{or}\ \mathbb{R}$)について満たすとする.
    このとき,
    \[ \log \ex[e^{\lambda(X-\ex[X])}] \le \frac{1}{2}\lambda^2\sigma^2 \ \ \ \mathrm{for\ all}\ \lambda\in I. \tag{3.6}\label{3.6} \]
\end{block}
\end{frame}

\begin{frame}{}
Remarks:
\begin{itemize}
    \item $I = \mathbb{R}$なら, (\ref{3.6})は$X-\ex[X]$がパラメータ$\sigma$のsub-Gauusianであることと同値.
    \item Chernoff argumentより, $I = [0, \infty)$でも片側tail-bound
    \[ \mathbb{P}[X \ge \ex[X]+t] \le e^{-\frac{t^2}{2\sigma^2}} \tag{3.7}\label{3.7}\]
    が得られ, $I=\mathbb{R}$なら両側tail bounds
    \[ \mathbb{P}[|X-\ex[X]|\ge t] \le 2e^{-\frac{t^2}{2\sigma^2}}\]
    となる.
\end{itemize}
\end{frame}

\begin{frame}{}{} 
{\bf Proof.}
\begin{itemize}
    \item $I = [0,\infty)$の場合のみ示す($I=\mathbb{R}$は演習とする).
    \item エントロピーのモーメント母関数による表現(\ref{3.3})と仮定(\ref{3.5})より,
    \[\mathbb{H}(e^{\lambda X}) = \lambda \varphi'(\lambda) - \varphi(\lambda)\log\varphi(\lambda)\le\frac{1}{2}\sigma^2\lambda^2\varphi(\lambda) \ \ \ \forall \lambda \ge 0.\tag{3.8}\label{3.8} \]
    \item 関数$G$を$G(\lambda):= \frac{1}{\lambda}\log\varphi(\lambda)\ (\lambda\ne 0)$と定義し, $\lambda=0$では連続性を満たすように
    \[ G(0):= \lim_{\lambda \to 0}G(\lambda) = \ex[X] \tag{3.9}\label{3.9}\]
    とする.
    \item $G'(\lambda) = \frac{1}{\lambda}\frac{\varphi'(\lambda)}{\varphi(\lambda)}-\frac{1}{\lambda^2}\log\varphi(\lambda)$より, (\ref{3.8})は$G'(\lambda) \le \frac{1}{2}\sigma^2$となるので, $\lambda_0(>0)$から$\lambda$まで両辺積分すると
    \[ G(\lambda) - G(\lambda_0) \le \frac{1}{2}\sigma^2(\lambda-\lambda_0). \]
    \item $\lambda_0 \downarrow 0$とすると
    \[ G(\lambda) - \ex[X] \le \frac{1}{2}\sigma^2\lambda \]
    となり, これは(\ref{3.6})と同値である.\qed
\end{itemize}
\end{frame}

\begin{frame}{}
\begin{itemize}
    \item 2章と同様に, 次はsub-exponential tailをもつ確率変数を考える.
\end{itemize}
\begin{block}{Proposition 3.3 (Bernsten entropy bound)}
    正整数$b, \sigma$が存在して, エントロピー$\mathbb{H}(e^{\lambda X})$は以下を満たすとする.
    \[
        \mathbb{H}(e^{\lambda x})
        \le \lambda^2\left\{b\varphi_X'(\lambda) + \varphi_X(\lambda)(\sigma^2-b\ex[X])\right\}
        \ \ \ \mathrm{for\ all}\ \lambda \in [0, 1/b).
        \tag{3.10}\label{3.10}
    \]
    このとき, 
    \[
        \log\ex[e^{\lambda(X-\ex[X])}] \le \sigma^2\lambda^2(1-b\lambda)^{-1}
        \ \ \ \mathrm{for\ all}\ \lambda \in [0, 1/b).
        \tag{3.11}\label{3.11}
    \]
\end{block}
Remarks:
\begin{itemize}
    \item Chernoff argumentより, Prop.3.3は以下のsub-exponential tailsをもつ変数の上側Bernstein-type boundを含意する.
    \[
        \mathbb{P}[X\ge\ex[X] + \delta]
        \le \exp\left(-\frac{\delta^2}{4\sigma^2+2b\delta}\right)
        \ \ \ \mathrm{for\ all}\ \delta \ge 0.
        \tag{3.12}\label{3.12}
    \]
\end{itemize}
\end{frame}

\begin{frame}{}{}
{\bf Proof.}
\begin{itemize}
    \item 一般性を失わずに$\ex[X] = 0$と$b = 1$を仮定できる(see Exercise 3.6).
    \item このとき(\ref{3.10})は次のように簡単化される.
    \[
        \mathbb{H}(e^{\lambda X})
        \le \lambda^2 \left\{\varphi'(\lambda) + \varphi(\lambda)\sigma^2\right\}
        \ \ \ \mathrm{for\ all}\ \lambda \in [0,1).
        \tag{3.13}\label{3.13}
    \]
    \item Prop.3.2の証明と同様に$G(\lambda) = \frac{1}{\lambda}\log \varphi(\lambda)$を定義すると,
    (\ref{3.13})は$G' \le \sigma^2 + \frac{\varphi'}{\varphi}$と同値になる.
    \item $\lambda_0 > 0$を任意にとり$\lambda_0$から$\lambda$まで両辺積分すると,
    \[
        G(\lambda) - G(\lambda_0)
        \le \sigma^2(\lambda-\lambda_0) + \log\varphi(\lambda) - \log \varphi(\lambda_0).
    \]
    \item $\lambda_0 \downarrow 0$とすると,
    $\lim_{\lambda\downarrow 0}G(\lambda_0) = \ex[X]$と$\log\varphi(0)=0$より,
    \[
        G(\lambda) - \ex[X] \le \sigma^2 \lambda + \log\varphi(\lambda)
        \tag{3.14}\label{3.14}
    \]
    となる.
    \item (\ref{3.14})に$G$と$\varphi$を入れて書き換えると(\ref{3.11})が得られる.\qed
\end{itemize}
\end{frame}

\subsection{3.1.3 Separately convex functions and the entropic method}
\begin{frame}{3.1.3 Separately convex functions and the entropic method}
\begin{itemize}
    \item Entropy methodは複数の確率変数からなる関数のconcentrationを考える時に強力.
    \item 関数$f:\mathbb{R}^n \to \mathbb{R}$が{\it separately convex}であるとは,
          各$k\in\{1,\dots,n\}$について1変数関数
          \[y_k \mapsto f(x_1,\dots,x_{k-1},y_k,x_{k+1},\dots,x_n)\]
          が任意の$(x_1,\dots,x_{k-1},x_{k+1},\dots,x_n) \in \mathbb{R}^{n-1}$に対して凸であることをいう.
    \item また関数$f$がユークリッドノルムに対して$L$-Lipschitzであるとは,
          \[
              \left|f(x)-f(x')\right| \le L \|x-x'\|
              \ \ \ \mathrm{for\ all}\ x,x'\in\mathbb{R}^n.
          \]
          が成り立つことをいう.
\end{itemize}
\end{frame}

\begin{frame}
\begin{block}{Theorem 3.4}
    $\{X_i\}_{i=1}^n$は独立な確率変数列でそれぞれのサポートは$[a,b]$に含まれるものとし,
    $f:\mathbb{R}^n\to\mathbb{R}$はseparately convexかつ$L$-Lipschitzであるとする.
    このとき, 任意の$\delta > 0$に対して
    \[
        \mathbb{P}\left[ f(X) \le \ex[f(X)] + \delta \right]
        \le \exp\left(-\frac{\delta^2}{4L^2(b-a)^2}\right)
        \tag{3.16}\label{3.16}
    \]
    が成り立つ.
\end{block}
{Remarks:}
\begin{itemize}
    \item この結果はGaussianヘ変数のLipscitz関数のupper tail boundを求めたThm.2.26のanalogueだが,
          独立かつboundedな変数に対して適用できる.
    \item ただし, separetely convexityの仮定は一般に取り除くことができない.
    \item $f$がjointly convexの場合はlower tail boundの導出に他のテクニックが使える(cf Thm.3.24).
\end{itemize}
\end{frame}

\begin{frame}
\begin{exampleblock}{Example 3.5 (Sharp bounds on Rademacher complexity)}
    \begin{itemize}
        \item 有界部分集合$\mathcal{A}\in\mathbb{R}^n$は所与とし,
        確率変数$Z = \sup_{a\in\mathcal{A}}\sum_{k=1}^na_k\epsilon_k$を考える.
        \item $\epsilon_k \in \{\-1,1\}$はi.i.d.なRademacher variables.
        \item $Z$は線形関数の$\sup$をとったものなのでjointly (したがってseparately) convex.
        \item 別の$Z' = Z(\epsilon')$に対し, 任意の$a\in\mathcal{A}$について
        \[
            \langle a,\epsilon\rangle - Z'
            = \langle a,\epsilon\rangle - \sup_{a'\in\mathcal{A}}\langle a,\epsilon'\rangle
            \le \langle a, \epsilon-\epsilon'\rangle
            \le \|a\|_2 \|\epsilon-\epsilon'\|_2.
        \]
        \item $a\in \mathcal{A}$について$\sup$をとると
        $Z-Z' \le \sup_{a\in\mathcal{A}}\|a\|_2\|\epsilon-\epsilon'\|$.
        \item よって, $Z$は$\mathcal{W}(\mathcal{A}):=\sup_{a\in\mathcal{A}}\|a\|_2\|$-Lipschitz.
        \item したがって, Theorem 3.4より
        \[ \mathcal{P}[Z \le \ex[Z]+t] \le \exp\left(-\frac{t^2}{16\mathcal{W}^2(\mathcal{A})}\right).
        \tag{3.17}\label{3.17}\]
        \item 通常$\mathcal{W}^2(A)$は$\sum_{k=1}^n\sup a_k^2$よりずっと小さいので, Example2.25より強いboundとなる.
    \end{itemize}
\end{exampleblock}
\end{frame}

% Example 3.6はとりあえず省略.

\subsection{3.1.4 Tensorization and separately convex functions}
\begin{frame}{3.1.4 Tensorization and separately convex functions}
\begin{itemize}
    \item 2つのlemmaをもとにTheorem 3.4を証明する.
\end{itemize}
\begin{block}{Lemma 3.7}
    $X, Y \sim \mathbb{P}$, i.i.d.とすると, 任意の関数$g:\mathbb{R}\to\mathbb{R}$に対し以下が成り立つ.
    \[
        \mathbb{H}(e^{\lambda g(X)})
        \le \lambda^2\ex\left[(g(X)-g(Y))^2e^{\lambda g(X)}\mathbb{I}[g(X)\ge g(Y)]\right]
        \ \ \ \mathrm{for\ all}\ \lambda > 0.
        \tag{3.20a}\label{3.20a}
    \]
    さらに$X$のサポートが$[a,b]$に含まれ, $g$が凸かつLipschitzなら,
    \[
        \mathbb{H}(e^{\lambda g(X)})
        \le \lambda^2(b-a)^2\ex\left[(g'(X))^2e^{\lambda g(X)}\right]
        \ \ \ \mathrm{for\ all}\ \lambda>0,
        \tag{3.20b}\label{3.20b}
    \]
    が成り立つ($g'$は$g$の導関数).
\end{block}
\end{frame}

\begin{frame}{}
\begin{itemize}
    \item Lemma 3.7は, 凸かつLipschitzな関数はほとんどいたるところ微分可能であるという事実を使っている(Rademacher's Theorem).
    \item また, $g$が$L$-Lipschitzなら$\|g'\|_\infty \le L$\footnote{関数$f$に対して$\|f\|_\infty$は$f$の本質的上限$\|f\|_\infty:=\inf\{C\ge 0: |f(x)| \le C \mathrm{\ almost\ every}\ x.\}$.}なので,
          (\ref{3.20b})は以下を含意する.
          \[
              \mathbb{H}(e^{\lambda  g(X)}) \le \lambda^2 L^2(b-a)^2\ex[e^{\lambda g(X)}]
              \ \ \ \mathrm{for\ all}\ \lambda > 0.
          \] 
    \item したがってProposition 3.2より
    \[ \mathbb{P}[g(X) \ge \ex[g(X)]+\delta] \le e^{-\frac{\delta^2}{4L^2(b-a)^2}} \]
    となるので, Lemma 3.7はTheorem 3.4の1変数バージョンをただちに導く.
    \item しかし(\ref{3.20b})では$L$でなく$g'$とより強いboundとなっており,
    これがTheorem 3.4の導出において重要となる.
\end{itemize}
\end{frame}

\begin{frame}{}{}
{\bf Proof of Lemma 3.7}
\begin{itemize}
    \item エントロピーの定義より,
\begin{align*}
    \mathbb{H}(e^{\lambda g(X)})
    &= \ex_X[\lambda g(X) e^{\lambda g(X)}] - \ex_X[e^{\lambda g(X)}]\log(\ex_Y[e^{\lambda g(Y)}])\\
    &\le \ex_X[\lambda g(X) e^{\lambda g(X)}] - \ex_{X,Y}[e^{\lambda g(X)}\lambda g(Y)] \tag{Jensen's inequality}\\
    &= \frac{1}{2} \ex_{X,Y}\left[\lambda\{g(X)-g(Y)\}\{e^{\lambda g(X)}-e^{\lambda g(Y)}\}\right] \\
    &= \lambda \ex\left[\{g(X)-g(Y)\}\{e^{\lambda g(X)}-e^{\lambda g(Y)}\}\mathbb{I}[g(X) \ge g(Y)]\right]. \tag{3.22}\label{3.22}
\end{align*}
    となる(ただし最後の等式は$X,Y$の対称性より).
\end{itemize}
\end{frame}

\begin{frame}{}
\begin{itemize}
    \item 指数関数の凸性より, 任意の$s\ge t$に対し$e^s - e^t \le e^s(s-t)$なので,
    \[ (s-t)(e^s-e^t)\mathbb{I}[s\ge t] \le (s-t)^2e^s\mathbb{I}[s\ge t] \]
    \item これを(\ref{3.22})に適用すると, (\ref{3.20a})
    \[
        \mathbb{H}(e^{\lambda g(X)})
        \le \lambda^2\ex[(g(X)-g(Y))^2 e^{\lambda g(X)} \mathbb{I}[g(X)\ge g(Y)]].
        \tag{3.23}\label{3.23}
    \]
    が得られる.
    \item さらに$g$が凸で$x,y\in[a,b]$とすると, $g(x)-g(y)\le g'(x)(x-y)$より,
    \[(g(x)-g(y))^2\mathbb{I}[g(x)\ge g(y)] \le (g'(x))^2(x-y)^2\le (g'(x))^2(b-a)^2\]
    となるので, これを(\ref{3.23})に適用すれば(\ref{3.20a})が得られる.\qed
\end{itemize}
\end{frame}

\end{document}